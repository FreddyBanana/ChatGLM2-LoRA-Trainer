python inference.py \
	--CUTOFF_LEN 256 \
	--MODEL_NAME THUDM/chatglm2-6b \
	--LORA_CHECKPOINT_DIR ./output_model/checkpoint-4000/ \
	--PROMPT hello